{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quarterly-harvest",
   "metadata": {},
   "source": [
    "# Exploration Project | 01. 가위바위보 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-solution",
   "metadata": {},
   "source": [
    "\n",
    "## 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-banks",
   "metadata": {},
   "source": [
    "라이브러리 임포트 (이미지 크기를 조정할 수 있도록 PIL 라이브러리를 가져온다.)\n",
    "순차적으로 필요한 다른 라이브러리는 해당 코드 블럭에서 임포트 하였음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "productive-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-brief",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "가위, 바위, 보 이미지를 28 * 28 사이즈로 변경해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "alpha-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  images to be resized.\n",
      "200  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 이미지 파일을 28x28 사이즈로 바꾸기\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t여서\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들이기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "automatic-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  images to be resized.\n",
      "200  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 이미지 파일을 28x28 사이즈로 바꾸기\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들이기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "catholic-communication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  images to be resized.\n",
      "200  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 이미지 파일을 28x28 사이즈로 바꾸기\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들이기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-tattoo",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "## 데이터 읽어들이기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-directory",
   "metadata": {},
   "source": [
    "numpy 라이브러리를 임포트한다. 데이터를 가져오는 함수를 작성한다. 입력 요소의 값을 0~1사이의 값으로 정규화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "roman-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 600 입니다.\n",
      "x_train shape: (600, 28, 28, 3)\n",
      "y_train shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=600): \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-asian",
   "metadata": {},
   "source": [
    "## 읽어들인 Training 데이터 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-stopping",
   "metadata": {},
   "source": [
    "읽어온 데이터가 내가 준비한 훈련용 데이터가 맞는지 확인한다. matplotlib 라이브러리를 임포트해서 이미지를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "imposed-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-johns",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-blind",
   "metadata": {},
   "source": [
    "케라스의 Sequential 모델을 사용하여 딥러닝 네크워크 모델을 만든다. sequential 모델을 사용하는 이유는 순차적으로 레이어 층을 더해주는 선형 방식이기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "published-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_397 (Conv2D)          (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_397 (MaxPoolin (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_398 (Conv2D)          (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_398 (MaxPoolin (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_399 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_399 (MaxPoolin (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_175 (Flatten)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 955,395\n",
      "Trainable params: 955,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# RGB 이미지이므로 흑백을 의미하는 1이 아니라 RGB를 나타내는 3으로 변경해야 한다.\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "# 가위, 바위, 보 3개의 클래스이므로 MNIST 데이터셋의 0~9까지 10개 클래스였던 것을 3개로 변경해야 한다.\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-state",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-touch",
   "metadata": {},
   "source": [
    "모델을 학습시키기 전에 compile메소드를 통해 학습방식을 설정해준다. optimizer는 정규화기, loss는 손실함수, metrics는 분류의 기준을 설정한다. fit함수를 사용하여 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "sublime-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 10s 537ms/step - loss: 20.6480 - accuracy: 0.3544\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 1.2279 - accuracy: 0.3671\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 1.0116 - accuracy: 0.4974\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.9150 - accuracy: 0.5947\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6865 - accuracy: 0.7593\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5682 - accuracy: 0.7481\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4666 - accuracy: 0.8206\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6531 - accuracy: 0.7382\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8450\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7908509190>"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10) #epochs 10까지 변경하면서 실행해 보고 결정 (반복학습횟수임)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-minute",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-pursuit",
   "metadata": {},
   "source": [
    "테스트 데이터도 훈련 데이터와 마찬가지로 resizing을 해준다. 데이터를 가져오는 함수를 작성한다. 입력 요소의 값을 0~1사이의 값으로 정규화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "respective-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "x_test_norm shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def resize_test_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일을 28x28 사이즈로 바꾸어 저장\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들임\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들임\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들임\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "def load_test_data(img_path, number_of_data=300):  \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"x_test_norm shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-philosophy",
   "metadata": {},
   "source": [
    "## 읽어들인 Test 데이터 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-nitrogen",
   "metadata": {},
   "source": [
    "읽어온 데이터가 내가 준비한 테스트용 데이터가 맞는지 확인한다. matplotlib 라이브러리를 임포트해서 이미지를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "brave-flush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[0])\n",
    "print('라벨: ', y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-crossing",
   "metadata": {},
   "source": [
    "##  test_accuracy 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-reference",
   "metadata": {},
   "source": [
    "테스트 세트에서 모델의 성능을 측정해 본다. 훈련 세트에서 보다 테스트 세트에서 accuracy가 낮은 이유는 overfitting 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "posted-design",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.0929 - accuracy: 0.6133\n",
      "test_loss: 1.092896580696106 \n",
      "test_accuracy: 0.6133333444595337\n"
     ]
    }
   ],
   "source": [
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-comparative",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "# [회고]\n",
    "\n",
    "## 오버피팅을 극복하기 위한 적절한 시도\n",
    "\n",
    "#### 1. 정규화 시도\n",
    "- kernel_regularizer=keras.regularizers.l2(0.001)\n",
    "- L2 정규화 시도 시 accuracy=44% --> 46%\n",
    "\n",
    "#### 2. 피쳐의 수 줄이기\n",
    "- n_channel_1, n_channel_2, n_dense를 조정하여 피쳐의 수를 감소시켜 보았음\n",
    "- 1) 32, 64, 32 설정 시 parameter 70,723, accuracy=34%\n",
    "- 2) 16, 32, 32 설정 시 parameter 30,819, accuracy=54%\n",
    "\n",
    "#### 3. epochs 조정해 보기\n",
    "- epochs=5,  accuracy=39%\n",
    "- epochs=10, accuracy=37%\n",
    "- epochs=15, accuracy=38%\n",
    "- epochs=18, accuracy=45%\n",
    "- epochs=19, accuracy=51%\n",
    "- epochs=20, accuracy=48%\n",
    "- epochs=30, accuracy=43%\n",
    "- epochs=40, accuracy=47%\n",
    "- epochs=50, accuracy=34%\n",
    "\n",
    "##### 정규화, 피쳐 수 조정, 반복학습 횟수조정을 통틀어 가장 높은 test_accuracy값은 54%임.\n",
    "##### 따라서, 데이터셋을 조정해야 함.\n",
    "\n",
    "## 데이터셋 조정\n",
    "- 손의 날선모양 같은, 구분이 모호한 이미지 8개를 삭제하고 가위 앞면 4개와 뒷면 4개로 대체하여 테스트함, accuracy=44%\n",
    "\n",
    "- 훈련데이터 100개씩 추가하여 총 600개로 테스트함, accuracy=47% epochs=9\n",
    "- 위 세팅에 정규화 적용시 accuracy=50%까지 올라감\n",
    "\n",
    "- 특정 각도의 손모양 여러사람 데이터를 대량 추가하여 1866개의 데이터로 테스트함, accuracy=52%, epochs=15\n",
    "- 위 세팅에 정규화 시도 시 accuracy=56%까지 올라감\n",
    "\n",
    "- 공통적으로 n_channel_1, n_channel_2, n_dense는 16, 32, 32일 때 가장 accuracy가 높게 나옴.\n",
    "- feature 값(n_channel_1, n_channel_2, n_dense)이 커질수록 정규화 시 accuracy가 내려감.\n",
    "\n",
    "- 데이터의 양을 증가시킬 시 accuracy 5~6% 증가. But, accuracy가 60%를 넘지 못함.\n",
    "- 정규화 시 3~4% 정도 accuracy가 증가함. But, accuracy가 60%를 넘지 못함.\n",
    "\n",
    "- 결국, 데이터의 양보다 데이터의 구성이 중요하다는 가설을 도출할 수 있음.\n",
    "\n",
    "#### 최종 결과 도출 세팅 값\n",
    "- 데이터의 개수는 훈련 600개, 테스트 300개로 하였음.\n",
    "- 훈련데이터의 대표이미지(ex.손바닥, 손등) 비중을 증가시키는 방법으로 데이터구성을 달리하여 최종 테스트.\n",
    "- feature값 n_channel_1, n_channel_2, n_channel_3, n_dense는 128, 256, 256, 256으로 설정 (레이어 하나 더 추가함)\n",
    "- epochs=10\n",
    "- test_accuracy=61%\n",
    "- 최종 결과 test_accuracy 60% 이상 도달!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
